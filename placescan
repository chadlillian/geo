#!/home/chad/anaconda/bin/python

# get all photo id's from mongodb, then run the urls through the CNN and populate mongodb with category scores
import  numpy as np
import  matplotlib.pyplot as plt
import  sys
import  caffe
import  time
import  os
import  glob
import  pickle
import  threading
import  Queue
from pymongo import MongoClient
import  requests
import  dashboard   as  dash
import  datetime
import  signal
import  cStringIO   as  StringIO
import  urllib
#   https://github.com/BVLC/caffe/issues/438
from skimage import io; io.use_plugin('matplotlib')

def handler(signum,frame):
    print 'Process Timed Out ',signum
    raise IOError("Image download timed out")

class caffeExec:
    def __init__(self):
        # Make sure that caffe is on the python path:
        self.caffe_root ='/home/chad/caffe/'  # this file is expected to be in {caffe_root}/examples

        pcnn_MODEL_FILE =self.caffe_root+'/models/placesCNN/places205CNN_deploy.prototxt'
        pcnn_PRETRAINED =self.caffe_root+'/models/placesCNN/places205CNN_iter_300000.caffemodel'
        pcnn_CATEGORIES =self.caffe_root+'/models/placesCNN/categoryIndex_places205.csv'
        pcnn_length     =205
        hcnn_MODEL_FILE =self.caffe_root+'/models/hybridCNN/hybridCNN_deploy.prototxt'
        hcnn_PRETRAINED =self.caffe_root+'/models/hybridCNN/hybridCNN_iter_700000.caffemodel'
        hcnn_CATEGORIES =self.caffe_root+'/models/hybridCNN/categoryIndex_hybridCNN.csv'
        hcnn_length     =1183

        pcnn_CATEGORIES =[q.split()[0] for q in open(pcnn_CATEGORIES).readlines()]
        hcnn_CATEGORIES =[q.split()[0] for q in open(hcnn_CATEGORIES).readlines()]

        self.models             ={'placesCNN':{'model':pcnn_MODEL_FILE, 'pretrained':pcnn_PRETRAINED, 'len':pcnn_length, 'categories':pcnn_CATEGORIES},
                                  'hybridCNN':{'model':hcnn_MODEL_FILE, 'pretrained':hcnn_PRETRAINED, 'len':hcnn_length, 'categories':hcnn_CATEGORIES}}
        self.client = MongoClient()
        self.monitor = dash.dashboard()
        #self.monitor.setURL('http://localhost:8080/')
        self.monitor.reset()

        
    def setup(self,model,database,collection):
        # Set the right path to your model definition file, pretrained model weights,
        # and the image you would like to classify.
        MODEL_FILE      =self.models[model]['model']
        PRETRAINED      =self.models[model]['pretrained']
        self.cnnlen     =self.models[model]['len']
        self.categories =self.models[model]['categories']
        
        numpymean   =np.load(self.caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1)
        caffe.set_mode_cpu()
        print("before load"*50)
        self.net        =caffe.Classifier(MODEL_FILE, PRETRAINED, mean=numpymean, channel_swap=(2,1,0), raw_scale=255, image_dims=(256, 256))
        print("after load"*50)

        self.db         =self.client[database]
        self.collection =self.db[collection]
        #self.images        =self.collection.find({'prediction':{'$exists':False}},timeout=False)
        qry ={"$or":[{'prediction':{'$exists':False}},{'prediction':0}]}
        self.images     =self.collection.find(qry,timeout=False)

    def predictMongoDB(self):
        sf  ={'predict':0,'fail':0}
        number  =self.images.count()
        for i,image in enumerate(self.images):
            start   =datetime.datetime.now()
            if image['height']*image['width']<9300*9300:
                try:
                    signal.signal(signal.SIGALRM,handler)
                    signal.alarm(300)

                    caffeImages         =[caffe.io.load_image(image['photo_file_url']) ]

                    signal.alarm(0)
                    prediction          =self.net.predict(caffeImages)[0].tolist()
                    prediction          =dict(zip(self.categories,prediction))
                    start2  =datetime.datetime.now()

                    a       =self.collection.update({'_id':image['_id']},{"$set":{'prediction':prediction}})
                    sf['predict']   =sf['predict']+1
                except:
                    a       =self.collection.update({'_id':image['_id']},{"$set":{'prediction':0}})
                    sf['fail']  =sf['fail']+1

                end =datetime.datetime.now()
                elaptime    =end-start
                elaptime    =elaptime.seconds+elaptime.microseconds*1e-6

                try:
                    print '%5i/%5i %80s predict %5i fail %5i [%s %f]'%tuple([i,number,image['photo_file_url'],sf['predict'],sf['fail'],start.strftime('%X'),elaptime])
                    self.monitor.update({'value':i,'application':'X'})
                except:
                    print image

    def scanImages(self):
        for i,image in enumerate(self.images):
            imageurl        =image['photo_file_url']
            print image
            signal.signal(signal.SIGALRM,handler)
            signal.alarm(5)
            try:
                caffeImages         =[caffe.io.load_image(imageurl)]
                flag    ='success'
            except:
                flag    ='fail'

            signal.alarm(0)

            print i,flag,image['_id'],image['photo_file_url']
        

co      =caffeExec()
#co.setup('placesCNN','geo','panoramio_barcelona')
#co.setup('placesCNN','geo','panoramio_popular')
#co.setup('placesCNN','geo','Singapore')
#co.setup('placesCNN','geo','Monaco')
#co.setup('placesCNN','geo','San Marino')
#co.setup('placesCNN','geo','Liechtenstein')
col =sys.argv[1].decode('utf-8')
co.setup('placesCNN','geo',col)
co.predictMongoDB()
#co.scanImages()
